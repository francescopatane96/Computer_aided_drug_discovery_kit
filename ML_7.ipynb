{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPjzv/xuCcgAj5/mA8huVns",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francescopatane96/Computer_aided_drug_discovery_kit/blob/main/ML_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit   #install rdkit library"
      ],
      "metadata": {
        "id": "sTiafVkFRvo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lazypredict  #install lazypredict"
      ],
      "metadata": {
        "id": "npXUo4YLmFLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/volkamerlab/teachopencadd.git  #install teachopencadd dependecies "
      ],
      "metadata": {
        "id": "L10Sz7LoR5f0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqMlkn50RdJD"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import seaborn as sns\n",
        "from warnings import filterwarnings\n",
        "import time\n",
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyRegressor\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import svm, metrics, clone\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import auc, accuracy_score, recall_score\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import MACCSkeys\n",
        "from rdkit.Chem.AllChem import GetMorganFingerprintAsBitVect\n",
        "\n",
        "from teachopencadd.utils import seed_everything\n",
        "\n",
        "# Silence some expected warnings\n",
        "filterwarnings(\"ignore\")\n",
        "# Fix seed for reproducible results\n",
        "SEED = 44\n",
        "seed_everything(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data (Lipinski)\n",
        "chembl_df = pd.read_csv(\n",
        "    \"IDH_compounds_lipinski.csv\",    #read lipinski's descriptors csv\n",
        "    index_col=0,\n",
        ")\n",
        "\n",
        "# Look at head\n",
        "print(\"Shape of dataframe : \", chembl_df.shape)\n",
        "chembl_df.head()\n"
      ],
      "metadata": {
        "id": "QWPd9haHSfne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature for proving and Proving our data \\\\ NaN finder\n",
        "def check_missing_values(dataframe):\n",
        "    \n",
        "    if dataframe.isnull().sum().sum() > 0:\n",
        "        m_total = dataframe.isnull().sum().sort_values(ascending=False) \n",
        "        total = m_total[m_total > 0]\n",
        "\n",
        "        m_percent = dataframe.isnull().mean().sort_values(ascending=False) \n",
        "        percent = m_percent[m_percent > 0] \n",
        "\n",
        "        missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "    \n",
        "        print(f'Total and Percentage of NaN:\\n {missing_data}')\n",
        "    else: \n",
        "        print('No NaN found.')\n",
        "        \n",
        "        \n",
        "check_missing_values(dataframe=chembl_df)"
      ],
      "metadata": {
        "id": "YFTwK2XPnXK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove NaN, if present\n",
        "chembl_df = chembl_df.dropna()"
      ],
      "metadata": {
        "id": "B0m1hX4InpUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chembl_df.shape"
      ],
      "metadata": {
        "id": "H_DaNn2An0wO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only the columns we want\n",
        "chembl_df = chembl_df[[\"molecule_chembl_id\", \"smiles\", \"pIC50\"]]\n",
        "chembl_df.head()\n"
      ],
      "metadata": {
        "id": "ui_bJaycSn6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add column for activity\n",
        "chembl_df[\"active\"] = np.zeros(len(chembl_df))\n",
        "\n",
        "# Mark every molecule as active with an pIC50 of >= 6.3, 0 otherwise\n",
        "chembl_df.loc[chembl_df[chembl_df.pIC50 >= 6.3].index, \"active\"] = 1.0\n",
        "\n",
        "# NBVAL_CHECK_OUTPUT\n",
        "print(\"Number of active compounds:\", int(chembl_df.active.sum()))\n",
        "print(\"Number of inactive compounds:\", len(chembl_df) - int(chembl_df.active.sum()))"
      ],
      "metadata": {
        "id": "8NqHNrxjS1Zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chembl_df.head()\n"
      ],
      "metadata": {
        "id": "oW3bY18rS8cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "install padel (descriptors calculator)"
      ],
      "metadata": {
        "id": "LFEo-goYsEyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://github.com/gromdimon/features/raw/main/padel.sh\n",
        "! wget https://github.com/gromdimon/features/raw/main/padel.zip"
      ],
      "metadata": {
        "id": "9fIJcheD2e8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip padel.zip"
      ],
      "metadata": {
        "id": "5dfNxKNO2ktS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selection = ['smiles', 'molecule_chembl_id']     #select columns we want to retain\n",
        "act_selected = chembl_df[selection]\n",
        "act_selected.to_csv('molecule.smi', sep='\\t', index=False, header=False )"
      ],
      "metadata": {
        "id": "5ga_3hCr2v7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cat molecule.smi | head -5\n",
        "! cat molecule.smi | wc -l"
      ],
      "metadata": {
        "id": "SMxFKWGY3Cfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat padel.sh   #read the script"
      ],
      "metadata": {
        "id": "PUPnFvOF3EAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash padel.sh    #run padel (it reads molecule.smi file that contains canonical form smiles)"
      ],
      "metadata": {
        "id": "P-xS8kRB3F9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actx = pd.read_csv('descriptors_output.csv') #padel generates a file called 'descriptors_output.csv'\n",
        "actx                                         "
      ],
      "metadata": {
        "id": "yvObjIU33gYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data (Lipinski)\n",
        "chembl_df = pd.read_csv(\n",
        "    \"IDH_compounds_lipinski.csv\",    #read chembl dataset\n",
        "    index_col=0,\n",
        ")"
      ],
      "metadata": {
        "id": "wKt24N8W_eHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chembl_df"
      ],
      "metadata": {
        "id": "sBTUfDdP--8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title optional (categorical classification)\n",
        "\n",
        "chembl_df = chembl_df[[\"ro5_fulfilled\"]]\n",
        "chembl_df.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "sYlNV1I3950q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_col = chembl_df[\"ro5_fulfilled\"]\n",
        "print(\"column to added from first dataframe to second:\")\n",
        "display(extracted_col)\n",
        "  \n",
        "actx = actx.join(extracted_col)\n",
        "print(\"Second dataframe after adding column from first dataframe:\")\n",
        "display(actx)"
      ],
      "metadata": {
        "id": "mTHDKC17AQiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chembl_df = actx"
      ],
      "metadata": {
        "id": "yThLetm0A9Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc_curves_for_models(models, test_x, test_y, save_png=False):\n",
        "    \"\"\"\n",
        "    Helper function to plot customized roc curve.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    models: dict\n",
        "        Dictionary of pretrained machine learning models.\n",
        "    test_x: list\n",
        "        Molecular fingerprints for test set.\n",
        "    test_y: list\n",
        "        Associated activity labels for test set.\n",
        "    save_png: bool\n",
        "        Save image to disk (default = False)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    fig:\n",
        "        Figure.\n",
        "    \"\"\"\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # Below for loop iterates through your models list\n",
        "    for model in models:\n",
        "        # Select the model\n",
        "        ml_model = model[\"model\"]\n",
        "        # Prediction probability on test set\n",
        "        test_prob = ml_model.predict_proba(test_x)[:, 1]\n",
        "        # Prediction class on test set\n",
        "        test_pred = ml_model.predict(test_x)\n",
        "        # Compute False postive rate and True positive rate\n",
        "        fpr, tpr, thresholds = metrics.roc_curve(test_y, test_prob)\n",
        "        # Calculate Area under the curve to display on the plot\n",
        "        auc = roc_auc_score(test_y, test_prob)\n",
        "        # Plot the computed values\n",
        "        ax.plot(fpr, tpr, label=(f\"{model['label']} AUC area = {auc:.2f}\"))\n",
        "\n",
        "    # Custom settings for the plot\n",
        "    ax.plot([0, 1], [0, 1], \"r--\")\n",
        "    ax.set_xlabel(\"False Positive Rate\")\n",
        "    ax.set_ylabel(\"True Positive Rate\")\n",
        "    ax.set_title(\"Receiver Operating Characteristic\")\n",
        "    ax.legend(loc=\"lower right\")\n",
        "    # Save plot\n",
        "    if save_png:\n",
        "        fig.savefig(f\"{DATA}/roc_auc\", dpi=300, bbox_inches=\"tight\", transparent=True)\n",
        "    return fig"
      ],
      "metadata": {
        "id": "COhODkg0TiVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_performance(ml_model, test_x, test_y, verbose=True):\n",
        "    \"\"\"\n",
        "    Helper function to calculate model performance\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ml_model: sklearn model object\n",
        "        The machine learning model to train.\n",
        "    test_x: list\n",
        "        Molecular fingerprints for test set.\n",
        "    test_y: list\n",
        "        Associated activity labels for test set.\n",
        "    verbose: bool\n",
        "        Print performance measure (default = True)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple:\n",
        "        Accuracy, sensitivity, specificity, auc on test set.\n",
        "    \"\"\"\n",
        "\n",
        "    # Prediction probability on test set\n",
        "    test_prob = ml_model.predict_proba(test_x)[:, 1]\n",
        "\n",
        "    # Prediction class on test set\n",
        "    test_pred = ml_model.predict(test_x)\n",
        "\n",
        "    # Performance of model on test set\n",
        "    accuracy = accuracy_score(test_y, test_pred)\n",
        "    sens = recall_score(test_y, test_pred)\n",
        "    spec = recall_score(test_y, test_pred, pos_label=0)\n",
        "    auc = roc_auc_score(test_y, test_prob)\n",
        "\n",
        "    if verbose:\n",
        "        # Print performance results\n",
        "        # NBVAL_CHECK_OUTPUT        print(f\"Accuracy: {accuracy:.2}\")\n",
        "        print(f\"Sensitivity: {sens:.2f}\")\n",
        "        print(f\"Specificity: {spec:.2f}\")\n",
        "        print(f\"AUC: {auc:.2f}\")\n",
        "\n",
        "    return accuracy, sens, spec, auc"
      ],
      "metadata": {
        "id": "lyGpuP7BTlyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_training_and_validation(ml_model, name, splits, verbose=True):\n",
        "    \"\"\"\n",
        "    Fit a machine learning model on a random train-test split of the data\n",
        "    and return the performance measures.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ml_model: sklearn model object\n",
        "        The machine learning model to train.\n",
        "    name: str\n",
        "        Name of machine learning algorithm: RF, SVM, ANN\n",
        "    splits: list\n",
        "        List of desciptor and label data: train_x, test_x, train_y, test_y.\n",
        "    verbose: bool\n",
        "        Print performance info (default = True)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple:\n",
        "        Accuracy, sensitivity, specificity, auc on test set.\n",
        "\n",
        "    \"\"\"\n",
        "    train_x, test_x, train_y, test_y = splits\n",
        "\n",
        "    # Fit the model\n",
        "    ml_model.fit(train_x, train_y)\n",
        "\n",
        "    # Calculate model performance results\n",
        "    accuracy, sens, spec, auc = model_performance(ml_model, test_x, test_y, verbose)\n",
        "\n",
        "    return accuracy, sens, spec, auc"
      ],
      "metadata": {
        "id": "nGak5nNLTpOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actx_final = actx.drop('Name', axis=1)\n",
        "actx_final"
      ],
      "metadata": {
        "id": "QFjG5IPQB6cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actx_df = actx_final.drop('ro5_fulfilled', axis=1)\n",
        "actx_df"
      ],
      "metadata": {
        "id": "eQbrzV_xFjZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chembl_df['ro5_fulfilled']"
      ],
      "metadata": {
        "id": "Lb1KnsZIFMHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data (Lipinski)\n",
        "chembl_df = pd.read_csv(\n",
        "    \"IDH_compounds_lipinski.csv\",\n",
        "    index_col=0,\n",
        ")\n"
      ],
      "metadata": {
        "id": "E5KBLpzUG-ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = actx_df               #descriptors\n",
        "Y = chembl_df.pIC50       #pIC50"
      ],
      "metadata": {
        "id": "vAEvKNRjHq8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spliting data in 80\\20 ratio\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=22)"
      ],
      "metadata": {
        "id": "_crBdOZvHzfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seeing the data that was prepared\n",
        "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
      ],
      "metadata": {
        "id": "ms4H8KktILlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defines and builds the lazyclassifier\n",
        "reg = LazyRegressor(verbose=0,ignore_warnings=True, custom_metric=None)\n",
        "models_train,predictions_train = reg.fit(X_train, X_train, Y_train, Y_train)"
      ],
      "metadata": {
        "id": "Hj5D9uZAIPNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance table of the training set (80% subset)\n",
        "models_train"
      ],
      "metadata": {
        "id": "FZBL_doEI4qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the study on a test sample\n",
        "reg = LazyRegressor(verbose=0,ignore_warnings=True, custom_metric=None)\n",
        "models_test,predictions_test = reg.fit(X_train,X_test,Y_train,Y_test)"
      ],
      "metadata": {
        "id": "qHNtZTdoJEJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_test"
      ],
      "metadata": {
        "id": "mxCFrrI_JU7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype('int32')\n",
        "Y_train = Y_train.astype('float64')"
      ],
      "metadata": {
        "id": "ekoYHjCWJ85J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "metadata": {
        "id": "_XihFXnfKF2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestRegressor(n_estimators=800, random_state=22)\n",
        "model.fit(X_train, Y_train)\n",
        "r2 = model.score(X_test, Y_test)\n",
        "r2                                 #show explained variance"
      ],
      "metadata": {
        "id": "jQRueafWKCGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try data with test sample\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "print(Y_pred)"
      ],
      "metadata": {
        "id": "IFcYvrWIKLvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the absolute errors\n",
        "\n",
        "errors = abs(Y_pred - Y_test)\n",
        "print('Mean absolute errors:', round(np.mean(errors), 2), 'degrees.')"
      ],
      "metadata": {
        "id": "dlf0wLSZKOqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate percentage of errors\n",
        "mape = 100 * (errors / Y_test)\n",
        "accuracy = 100 - np.mean(mape)\n",
        "print('Accuracy:', round(accuracy, 2), '%.')"
      ],
      "metadata": {
        "id": "4BR6pPliKSdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "generate model as joblib Object"
      ],
      "metadata": {
        "id": "LaTzuIhrviJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib"
      ],
      "metadata": {
        "id": "wL73UzIj1dDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(model, \"./random_forest.joblib\")    #save the model"
      ],
      "metadata": {
        "id": "ohKdeEYr1aub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_rf = joblib.load(\"./random_forest.joblib\")    #load the model"
      ],
      "metadata": {
        "id": "npsMsHmf1per"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_rf.predict(actx_df)              #predict pIC50"
      ],
      "metadata": {
        "id": "OumE5xsW1rTs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}